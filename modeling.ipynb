{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Notebook\n",
    "\n",
    "In this notebook, we will be training a regression model from the data produced from the `Data_Prep` Notebook. We will try two different models:\n",
    "- Simple Linear Regression using sklearn\n",
    "- Simple Neural Network using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Load Train and Test Data\n",
    "First we will load the train and test data for the current directory. Then we will split the data into train/validation sets with an 80/20 split, respectively. We will then want to scale the data since we are using a distance based evaluation metric. We can use sklearn's `scale` method to center the data around the mean for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('cleaned_train_data.csv')\n",
    "test_data = pd.read_csv('formatted_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['key', 'fare_amount'], axis=1)\n",
    "y = train_data['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scale(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(model, train_data, train_labels, val_data, val_labels, test_data):\n",
    "    '''\n",
    "    Predict outcomes for a given model.\n",
    "    Compute RMSE for both train and validation sets.\n",
    "    Construct the test csv and save it to current directory.\n",
    "    '''\n",
    "    train_preds = model.predict(train_data)\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_labels, train_preds))\n",
    "    val_preds = model.predict(val_data)\n",
    "    val_rmse = np.sqrt(mean_squared_error(val_labels, val_preds))\n",
    "    print(f'Train RMSE: {train_rmse}')\n",
    "    print(f'Validation RMSE: {val_rmse}')\n",
    "    \n",
    "    keys = test_data['key']\n",
    "    X_test = scale(test_data.drop('key', axis=1))\n",
    "    test_df = pd.DataFrame(columns = ['key','fare_amount'])\n",
    "    test_df['key'] = keys\n",
    "    test_df['fare_amount'] = model.predict(X_test)\n",
    "    test_df.to_csv('submission.csv', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model\n",
    "\n",
    "Create a simple Linear Regression model to find out where our base estimate is at. We can do this using sklearn, along with the `predict_score()` function we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3.847982441777744\n",
      "Validation RMSE: 3.842296488675296\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression().fit(X_scale, y_train)\n",
    "predict_score(lr_model, X_scale, y_train, X_val, y_val, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Although the RMSE seems to perform well on the train and validation sets, when submitting the test data to kaggle the RMSE is 5.498. This could mean that the model is not generalizing well when presented with new data (although it did perform well on the validation set). Again, this could be because the test data is cleaner than the validation set and therefore our model is not predicting as accurate as we would want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "We will now create a simple Neural Network to be used to predict the fare amount. Note that the competition suggested using a NN as the model architecture, so we will most likely see improvements from the Linear Regression model. We will create a NN with 5 layers, with 10 input nodes and 1 output node. We will use mean-squared-error as our loss/metric along with the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "97051/97051 [==============================] - 67s 685us/step - loss: 11.7426 - mse: 11.7426\n",
      "Epoch 2/20\n",
      "97051/97051 [==============================] - 63s 647us/step - loss: 9.8380 - mse: 9.83800s - loss: 9.8387\n",
      "Epoch 3/20\n",
      "97051/97051 [==============================] - 63s 653us/step - loss: 9.6739 - mse: 9.6739\n",
      "Epoch 4/20\n",
      "97051/97051 [==============================] - 63s 647us/step - loss: 9.5004 - mse: 9.5004\n",
      "Epoch 5/20\n",
      "97051/97051 [==============================] - 62s 635us/step - loss: 9.3137 - mse: 9.3137\n",
      "Epoch 6/20\n",
      "97051/97051 [==============================] - 59s 611us/step - loss: 9.2684 - mse: 9.2684\n",
      "Epoch 7/20\n",
      "97051/97051 [==============================] - 64s 662us/step - loss: 9.2999 - mse: 9.2999\n",
      "Epoch 8/20\n",
      "97051/97051 [==============================] - 62s 641us/step - loss: 9.2139 - mse: 9.2139\n",
      "Epoch 9/20\n",
      "97051/97051 [==============================] - 62s 641us/step - loss: 9.2329 - mse: 9.2329\n",
      "Epoch 10/20\n",
      "97051/97051 [==============================] - 63s 651us/step - loss: 9.1368 - mse: 9.1368\n",
      "Epoch 11/20\n",
      "97051/97051 [==============================] - 65s 672us/step - loss: 9.0491 - mse: 9.0491\n",
      "Epoch 12/20\n",
      "97051/97051 [==============================] - 64s 659us/step - loss: 9.0410 - mse: 9.0410\n",
      "Epoch 13/20\n",
      "97051/97051 [==============================] - 63s 650us/step - loss: 9.0614 - mse: 9.0614\n",
      "Epoch 14/20\n",
      "97051/97051 [==============================] - 59s 611us/step - loss: 8.9856 - mse: 8.98560s - loss: 8.98\n",
      "Epoch 15/20\n",
      "97051/97051 [==============================] - 61s 628us/step - loss: 9.0620 - mse: 9.0620\n",
      "Epoch 16/20\n",
      "97051/97051 [==============================] - 60s 622us/step - loss: 9.0334 - mse: 9.0334\n",
      "Epoch 17/20\n",
      "97051/97051 [==============================] - 60s 622us/step - loss: 8.9876 - mse: 8.9876\n",
      "Epoch 18/20\n",
      "97051/97051 [==============================] - 63s 651us/step - loss: 8.9683 - mse: 8.9683\n",
      "Epoch 19/20\n",
      "97051/97051 [==============================] - 61s 624us/step - loss: 8.9683 - mse: 8.9683\n",
      "Epoch 20/20\n",
      "97051/97051 [==============================] - 61s 626us/step - loss: 9.0052 - mse: 9.0052\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4, restore_best_weights=True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "history = model.fit(X_scale, y_train, epochs=20, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 2.9712101333744\n",
      "Validation RMSE: 2.9905416112836236\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>9.888168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>11.714224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>5.338974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>9.606993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>14.983194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key  fare_amount\n",
       "0  2015-01-27 13:08:24.0000002     9.888168\n",
       "1  2015-01-27 13:08:24.0000003    11.714224\n",
       "2  2011-10-08 11:53:44.0000002     5.338974\n",
       "3  2012-12-01 21:12:12.0000002     9.606993\n",
       "4  2012-12-01 21:12:12.0000003    14.983194"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score(model, X_scale, y_train, X_val, y_val, test_data)\n",
    "\n",
    "submission = pd.read_csv('submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Beginning with the Linear Regression model, our RMSE was around 5.498 which was on the lower end of the leaderboard. By using a simple Neural Network with 5 layers, we were able to lower the RMSE to around 3.856. This was a huge improvement from the previous model, and moved us up around +300 in the leaderboards. There is still room for improvement on our model (possibly longer training than we had done here) but overall we were able to acheive a desirable score. \n",
    "\n",
    "Discovering trends in our data and engineering new features such as the distance in kilometers per trip and extracting information for the date/time, we were able to successfully predict the fare amount that would be expected for a NYC taxi rider within a resonable range. We were able to eliminate most outliers in the data and this was a major part in the success of the model, although more cleaning and analysis could most likely be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
