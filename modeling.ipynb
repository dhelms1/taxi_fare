{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Notebook\n",
    "\n",
    "In this notebook, we will be training a regression model from the data produced from the `Data_Prep` Notebook. We will try two different models:\n",
    "- Simple Linear Regression using sklearn\n",
    "- Simple Neural Network using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Load Train and Test Data\n",
    "First we will load the train and test data for the current directory. Then we will split the data into train/validation sets with an 80/20 split, respectively. We will then want to scale the data since we are using a distance based evaluation metric. We can use sklearn's `scale` method to center the data around the mean for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('cleaned_train_data.csv')\n",
    "test_data = pd.read_csv('formatted_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(['key', 'fare_amount'], axis=1)\n",
    "y = train_data['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = scale(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_score(model, train_data, train_labels, val_data, val_labels, test_data):\n",
    "    '''\n",
    "    Predict outcomes for a given model.\n",
    "    Compute RMSE for both train and validation sets.\n",
    "    Construct the test csv and save it to current directory.\n",
    "    '''\n",
    "    train_preds = model.predict(train_data)\n",
    "    train_rmse = np.sqrt(mean_squared_error(train_labels, train_preds))\n",
    "    val_preds = model.predict(val_data)\n",
    "    val_rmse = np.sqrt(mean_squared_error(val_labels, val_preds))\n",
    "    print(f'Train RMSE: {train_rmse}')\n",
    "    print(f'Validation RMSE: {val_rmse}')\n",
    "    \n",
    "    keys = test_data['key']\n",
    "    X_test = scale(test_data.drop('key', axis=1))\n",
    "    test_df = pd.DataFrame(columns = ['key','fare_amount'])\n",
    "    test_df['key'] = keys\n",
    "    test_df['fare_amount'] = model.predict(X_test)\n",
    "    test_df.to_csv('submission.csv', index=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model\n",
    "\n",
    "Create a simple Linear Regression model to find out where our base estimate is at. We can do this using sklearn, along with the `predict_score()` function we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3.847982441777744\n",
      "Validation RMSE: 3.842296488675296\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression().fit(X_scale, y_train)\n",
    "predict_score(lr_model, X_scale, y_train, X_val, y_val, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Although the RMSE seems to perform well on the train and validation sets, when submitting the test data to kaggle the RMSE is 5.498. This could mean that the model is not generalizing well when presented with new data (although it did perform well on the validation set). Again, this could be because the test data is cleaner than the validation set and therefore our model is not predicting as accurate as we would want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "We will now create a simple Neural Network to be used to predict the fare amount. Note that the competition suggested using a NN as the model architecture, so we will most likely see improvements from the Linear Regression model. We will create a NN with 5 layers, with 10 input nodes and 1 output node. We will use mean-squared-error as our loss/metric along with the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "97051/97051 [==============================] - 67s 681us/step - loss: 12.0012 - mse: 12.0012\n",
      "Epoch 2/5\n",
      "97051/97051 [==============================] - 65s 670us/step - loss: 9.9189 - mse: 9.9189\n",
      "Epoch 3/5\n",
      "97051/97051 [==============================] - 66s 682us/step - loss: 9.5957 - mse: 9.5957\n",
      "Epoch 4/5\n",
      "97051/97051 [==============================] - 68s 696us/step - loss: 9.4390 - mse: 9.4390\n",
      "Epoch 5/5\n",
      "97051/97051 [==============================] - 65s 668us/step - loss: 9.4537 - mse: 9.45370s - loss: 9.4542 - mse\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a9019165c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "model.fit(X_scale, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3.0538828973591214\n",
      "Validation RMSE: 3.062841607273841\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-27 13:08:24.0000002</td>\n",
       "      <td>10.224867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-27 13:08:24.0000003</td>\n",
       "      <td>11.021889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-08 11:53:44.0000002</td>\n",
       "      <td>5.217670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-01 21:12:12.0000002</td>\n",
       "      <td>8.711488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-12-01 21:12:12.0000003</td>\n",
       "      <td>14.700125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           key  fare_amount\n",
       "0  2015-01-27 13:08:24.0000002    10.224867\n",
       "1  2015-01-27 13:08:24.0000003    11.021889\n",
       "2  2011-10-08 11:53:44.0000002     5.217670\n",
       "3  2012-12-01 21:12:12.0000002     8.711488\n",
       "4  2012-12-01 21:12:12.0000003    14.700125"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_score(model, X_scale, y_train, X_val, y_val, test_data)\n",
    "\n",
    "submission = pd.read_csv('submission.csv')\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Beginning with the Linear Regression model, our RMSE was around 5.498 which was on the lower end of the leaderboard. By using a simple Neural Network with 5 layers, we were able to lower the RMSE to around 3.91. This was a huge improvement from the previous model, and moved us up around +300 in the leaderboards. There is still room for improvement on our model (possibly longer training than we had done here) but overall we were able to acheive a desirable score. \n",
    "\n",
    "Discovering trends in our data and engineering new features such as the distance in kilometers per trip and extracting information for the date/time, we were able to successfully predict the fare amount that would be expected for a NYC taxi rider within a resonable range. We were able to eliminate most outliers in the data and this was a major part in the success of the model, although more cleaning and analysis could most likely be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
